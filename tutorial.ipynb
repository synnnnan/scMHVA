{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01982add",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shiyinan/anaconda3/envs/py38/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "from torch.utils.data import DataLoader\n",
    "from model import mhVAE\n",
    "from train import train_model,pretrain_model\n",
    "from util import setup_seed\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from preprocess import  geneSelection,my_normalize\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score,adjusted_mutual_info_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import scipy.io as sio\n",
    "import anndata as ad\n",
    "import scipy\n",
    "import scipy as sp\n",
    "\n",
    "import h5py\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9634250",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3590899/3343788062.py:15: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  adata1=ad.AnnData(rna)\n",
      "/tmp/ipykernel_3590899/3343788062.py:16: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  adata2=ad.AnnData(pro)\n"
     ]
    }
   ],
   "source": [
    "### read datasets\n",
    "path = '/data/'\n",
    "\n",
    "ctfile = '10x1kpbmc_label.mat'\n",
    "\n",
    "\n",
    "celltype_data = sio.loadmat(path+ctfile)\n",
    "celltype=celltype_data['y']\n",
    "data = celltype_data['X']\n",
    "rna=data[0][1][:,:,0]\n",
    "pro = data[0][0][:,:,0]\n",
    "\n",
    "\n",
    "adata1=ad.AnnData(rna)\n",
    "adata2=ad.AnnData(pro)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f829b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen offset: 0.68\n",
      "(713, 517)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "setup_seed(42)\n",
    "data1_=geneSelection(adata1.X, threshold=0, atleast=10, yoffset=.02, xoffset=5, decay=1.5, n=500, plot=False, markers=None, genes=None, figsize=(6,3.5),markeroffsets=None, labelsize=10, alpha=1, verbose=1)\n",
    "data1=adata1[:,data1_]\n",
    "data1 = my_normalize(data1,size_factors=True, normalize_input=True, logtrans_input=True)\n",
    "\n",
    "data2 = my_normalize(adata2,size_factors=True, normalize_input=True, logtrans_input=True)\n",
    "\n",
    "citeseq1= np.concatenate([data1.X,data2.X], axis=1)\n",
    "print(citeseq1.shape)\n",
    "\n",
    "nfeatures_rna = data1.shape[1]\n",
    "nfeatures_pro = data2.shape[1]\n",
    "## parameters\n",
    "batch_size = 128\n",
    "epochs_per_cycle =1\n",
    "epochs = epochs_per_cycle*100\n",
    "lr = 0.01\n",
    "z_dim = 100\n",
    "hidden_rna2 =200\n",
    "hidden_pro2 =200\n",
    "\n",
    "citeseq=pd.DataFrame(citeseq1)\n",
    "train_data=citeseq.to_numpy(dtype=np.float32)\n",
    "\n",
    "# load data\n",
    "train_transformed_dataset = train_data\n",
    "train_dl = DataLoader(train_transformed_dataset, batch_size=batch_size,shuffle=False, num_workers=0,drop_last=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db85212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = mhVAE(num_features=[nfeatures_rna,nfeatures_pro], num_hidden_features=[hidden_rna2,hidden_pro2], z_dim=z_dim).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f751ad3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:04<00:00, 11.44it/s]\n"
     ]
    }
   ],
   "source": [
    "pretrain_model(model,train_dl,lr,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2a7e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:05<00:00, 17.24it/s]\n"
     ]
    }
   ],
   "source": [
    "##cuda = True if torch.cuda.is_available() else False\n",
    "model,history,embedding=train_model(model, train_dl, lr, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df0f9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 5,n_init=20)\n",
    "consensus_labels = kmeans.fit_predict(embedding[0])\n",
    "consensus_labels=kmeans.labels_\n",
    "#print(consensus_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa96ae8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 0 0 0 0 2 2 2 0 0 2 0 0 0 4 2 2 2 2 1 2 0 1 0 2 3 1 4 0 0 1 4 0 3 1 0 2\n",
      " 4 1 3 0 0 2 0 0 4 0 0 0 4 4 1 3 0 2 2 0 3 1 4 1 0 0 0 4 0 2 1 2 3 1 0 1 3\n",
      " 2 0 2 0 0 0 0 2 3 3 1 3 1 2 4 4 1 3 2 3 0 0 4 1 0 0 1 0 0 2 0 3 0 3 0 2 3\n",
      " 1 4 0 0 3 0 3 1 4 3 3 3 1 0 4 1 0 0 2 1 1 0 0 3 2 3 0 3 2 0 1 0 0 4 0 2 2\n",
      " 2 2 4 3 2 3 0 0 0 1 2 2 2 1 1 0 3 2 2 3 3 3 0 3 0 2 4 2 4 1 2 4 0 0 1 0 2\n",
      " 0 1 0 0 4 3 3 3 1 1 4 0 1 1 1 4 1 1 0 1 3 2 3 0 3 2 3 0 3 2 2 1 0 1 2 3 2\n",
      " 0 1 1 1 2 3 2 4 0 1 1 2 0 1 0 3 4 3 1 4 0 4 1 1 2 0 0 0 0 3 4 2 3 2 2 3 3\n",
      " 0 0 0 0 3 1 0 0 0 0 2 1 1 0 2 1 0 3 3 3 3 1 3 2 1 0 0 4 3 0 1 0 1 1 0 3 0\n",
      " 3 0 0 2 0 3 2 0 4 1 2 1 0 1 1 0 3 3 0 1 1 4 0 1 0 0 2 1 0 0 0 3 1 1 3 3 3\n",
      " 3 3 3 0 1 3 2 3 3 1 2 3 3 0 1 0 0 0 0 4 2 1 2 0 0 4 2 3 0 0 2 4 1 0 4 1 0\n",
      " 1 2 0 0 0 3 2 2 1 0 2 3 1 2 0 2 0 1 1 3 0 2 2 3 0 0 0 0 0 4 1 0 4 4 0 2 1\n",
      " 0 0 3 3 3 2 1 4 0 2 0 0 1 1 0 0 3 2 0 4 4 0 3 3 0 1 0 1 1 2 0 0 1 0 0 4 3\n",
      " 4 2 3 4 0 1 0 1 4 3 2 2 0 0 2 0 1 4 0 2 1 4 0 2 1 0 1 4 1 0 1 0 0 1 2 0 1\n",
      " 2 1 1 1 4 0 3 4 0 2 3 4 3 1 0 0 0 1 4 1 2 3 3 4 0 1 0 1 0 3 4 4 0 2 4 2 0\n",
      " 1 0 3 0 0 4 4 1 3 1 0 3 1 2 3 2 3 2 1 4 3 0 2 2 2 1 1 2 0 0 0 0 1 0 3 1 2\n",
      " 2 0 1 3 1 3 1 0 3 3 0 0 1 4 2 0 0 2 1 3 0 3 1 0 3 3 1 3 0 3 3 0 4 3 1 2 0\n",
      " 4 0 3 1 0 0 0 2 4 2 1 2 0 0 1 4 3 0 2 3 3 0 1 3 1 4 0 2 2 2 2 1 0 3 1 1 2\n",
      " 4 2 0 0 2 4 1 4 3 2 3 0 1 0 1 4 1 4 2 0 2 0 0 0 1 3 1 0 3 1 1 2 0 2 0 2 1\n",
      " 0 2 4 4 3 1 2 1 4 2 0 1 3 0 2 1 2 0 3 0 3 1 1 1 0 0 1 4 0 0 1 1 0 4 4 4 0\n",
      " 2 1 0 0 3 0 1 3 2 4]\n",
      "[1 0 0 1 3 2 2 2 0 0 2 0 0 0 1 2 2 2 3 4 2 0 4 0 3 3 4 1 0 0 4 1 0 3 4 0 3\n",
      " 1 4 3 0 0 3 0 0 1 0 0 0 1 1 4 3 0 3 2 0 3 4 1 4 0 0 0 1 0 2 4 2 3 4 0 4 3\n",
      " 2 0 3 0 0 0 0 3 3 3 4 3 4 3 2 1 4 3 3 3 0 0 1 4 0 0 4 0 0 3 0 3 0 3 0 3 3\n",
      " 4 1 0 0 3 0 3 4 1 3 3 3 4 0 1 4 0 0 2 4 4 0 0 3 3 3 0 3 3 0 4 0 0 1 0 2 2\n",
      " 2 3 1 3 3 3 0 0 0 4 2 2 2 4 4 0 3 2 2 3 3 3 0 3 0 2 1 2 1 0 3 1 0 0 4 0 2\n",
      " 0 4 0 0 1 3 3 3 4 4 1 0 4 4 4 1 4 4 0 4 3 2 3 0 3 3 3 0 3 3 2 4 0 4 2 3 3\n",
      " 0 4 4 4 2 3 2 3 0 4 4 2 0 4 0 3 1 3 4 1 0 1 4 4 2 0 0 0 0 3 1 3 3 2 3 3 3\n",
      " 0 0 0 0 3 4 0 0 0 0 3 4 0 0 2 4 0 3 3 3 3 4 3 2 4 0 0 1 3 0 4 0 4 4 0 3 0\n",
      " 3 0 0 2 0 3 2 0 1 4 2 4 4 4 4 0 3 3 0 4 4 1 0 4 0 0 2 4 0 0 0 3 4 4 3 3 3\n",
      " 3 3 3 0 4 3 2 3 3 4 3 3 3 0 4 0 0 0 0 1 2 4 3 0 0 1 2 3 0 0 2 1 4 0 1 4 0\n",
      " 4 2 0 0 0 3 3 3 4 0 2 3 4 2 0 3 0 4 4 3 0 2 2 3 0 0 0 0 0 2 4 0 1 1 0 2 4\n",
      " 0 0 3 3 3 3 4 1 0 3 0 0 4 4 0 0 3 2 0 2 1 0 3 3 0 4 0 4 4 3 0 0 4 0 0 1 3\n",
      " 1 2 3 0 0 4 0 4 1 3 3 3 0 0 2 0 4 1 0 3 4 1 0 3 4 0 4 1 4 0 4 0 0 4 2 0 4\n",
      " 2 4 4 4 1 0 3 1 0 2 3 1 3 4 0 0 0 4 1 4 2 3 3 1 0 4 0 4 0 3 1 1 0 2 1 3 0\n",
      " 4 0 3 0 0 1 1 4 3 4 0 3 4 2 3 2 3 2 4 1 3 0 2 2 2 4 4 2 0 0 0 0 4 0 3 4 2\n",
      " 2 0 4 3 4 3 4 0 3 3 0 0 4 1 3 0 0 2 4 3 0 3 0 0 3 3 4 3 0 3 3 0 1 3 4 3 0\n",
      " 1 0 3 4 0 0 0 3 1 3 4 3 0 0 4 1 3 0 2 3 3 0 4 3 4 1 0 2 3 2 2 4 0 3 4 4 2\n",
      " 1 3 0 0 3 1 4 1 3 2 3 0 4 0 4 1 4 1 2 0 3 0 0 0 4 3 4 0 3 4 4 3 0 3 0 3 4\n",
      " 0 2 1 1 3 4 2 4 0 3 0 4 3 0 3 4 3 0 3 0 3 4 4 4 0 0 4 1 0 0 4 4 0 1 1 1 0\n",
      " 3 4 0 0 3 0 4 3 2 1]\n",
      "ARI: 0.846245495608417\n",
      "NMI: 0.8552661272362053\n",
      "AMI: 0.854186872942026\n",
      "ACC: 0.9116409537166901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shiyinan/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_encoder = LabelEncoder()\n",
    "true_labels_numeric = label_encoder.fit_transform(celltype)\n",
    "consensus_labels_series = pd.Series(consensus_labels)\n",
    "consensus_labels_encoded = label_encoder.fit_transform(consensus_labels_series)\n",
    "\n",
    "ari = adjusted_rand_score(true_labels_numeric, consensus_labels_encoded)\n",
    "nmi = normalized_mutual_info_score(true_labels_numeric, consensus_labels_encoded)\n",
    "ami = adjusted_mutual_info_score(true_labels_numeric, consensus_labels_encoded)\n",
    "\n",
    "def cluster_acc(y_true, y_pred):\n",
    "    y_true = y_true.astype(np.int64)\n",
    "    assert y_pred.size == y_true.size\n",
    "    D = max(y_pred.max(), y_true.max()) + 1\n",
    "    w = np.zeros((D, D), dtype=np.int64)\n",
    "    for i in range(y_pred.size):\n",
    "        w[y_pred[i], y_true[i]] += 1  \n",
    "    row_ind, col_ind = linear_sum_assignment(w.max() - w) \n",
    "    return sum([w[i, j] for i, j in zip(row_ind, col_ind)]) * 1.0 / y_pred.size\n",
    "acc=cluster_acc(true_labels_numeric, consensus_labels_encoded)\n",
    "\n",
    "print(true_labels_numeric)\n",
    "print(consensus_labels_encoded)\n",
    "print(\"ARI:\", ari)\n",
    "print(\"NMI:\", nmi)\n",
    "print(\"AMI:\", ami)\n",
    "print(\"ACC:\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734b422c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
